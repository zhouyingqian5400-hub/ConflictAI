【产品名称】ConflictAI

【需求详解】
1. 首页
    1.1 标题文本内容：人机交互实验，字体颜色3F37C9，黑体，40号，
        - 副标题文本内容为“选择一个AI模型并输入聊天室代码，与智能调解专家展开对话”，字体颜色64748B，黑体，16号
    1.2 聊天室代码栏
        - 文本框名称：聊天室代码，字体颜色2B2D42，黑体，16号
        - 文本框类型：输入框
        - 功能描述：默认随机生成一个代码，代码规则为“CHAT-xxx”，xxx为数字
            - 当用户直接点击 【进入聊天室】时，自动进入默认代码对应的聊天室
            - 当用户输入代码并点击 【进入聊天室】时，进入输入代码对应的聊天室
            - 错误规则：聊天室内最多有三人存在，当聊天室内已有三人时，显示 “聊天室已满”；当聊天室代码无对应聊天室时，弹窗显示 “代码无效”
    1.3 AI模型选项栏
        - 文本框名称：选择您要交互的AI模型，字体颜色2B2D42，黑体，16号
            - 文本框类型：单选选项，选项为 “叙事型说服者” 和 “论证型说服者”，字体颜色2B2D42，黑体，32号
        - 功能描述：点击后，进入对应类型的AI聊天室
    1.4 进入聊天室的按钮
        - 组件类型：按钮
        - 功能描述：点击后，进入聊天室
    1.5 首页逻辑与交互
        - 默认生成聊天室代码：页面加载时生成 `CHAT-xxx`（3 位数字），填入“聊天室代码”输入框。提供“刷新”图标按钮可重新生成。
        - 代码输入校验：输入框仅允许 `CHAT-` 前缀 + 3 位数字，失焦或点击按钮时校验；格式错误提示“代码格式应为 CHAT-xxx”。
        - AI 模型选择：单选两项“叙事型说服者”“论证型说服者”，默认选中第一项。选中后高亮卡片/单选按钮。
        - 进入聊天室按钮：
        - 点击时校验：代码格式、是否选择模型。
        - 调用后端 `GET /rooms/{code}/status`：
            - 不存在：弹窗“代码无效”。
            - 人数≥3：弹窗“聊天室已满”。
            - 否则进入聊天室页面，并携带 code、模型类型。
        - 反馈与态提示：点击后按钮进入加载态（spinner/禁用），接口返回后恢复。
    
2. 聊天室页面
    2.1 基本采用普遍AI chatbot的设计方式。
        - 功能描述：两个用户会进入同一个聊天室，但是他们是被隔离开与AI对话的。比如甲、乙为一组被试，他们进入聊天时候分别向AI表达观点，AI会基于甲的观点找寻核心矛盾点，向乙输出内容，反之亦然。也就是说，甲的观点是AI向乙对话的学习材料。
        
        具体规则：
        
        【阶段一：等待阶段】
        1、当聊天室用户不满两人时，禁止开始对话。
            - 显示状态：页面显示"等待其他用户加入..."的提示
            - 输入框状态：禁用输入框和发送按钮
            - 实时检测：每3秒轮询一次聊天室人数，当达到2人时自动进入下一阶段
            - 超时处理：如果30秒内未满2人，显示"等待超时，请刷新页面重试"
        
        【阶段二：对话启动阶段】
        2、当聊天室用户满两人时，对话可以开启，AI聊天机器人从 "我已经基本了解情况了，请问能跟我讲讲你对这个矛盾的想法吗？你是怎么想的？" 开始，此时用户甲、乙皆可看到这句话。
            - 触发时机：检测到聊天室人数达到2人时
            - 问候语发送：系统自动发送统一的启动消息（所有用户可见）
            - 输入框激活：此时输入框和发送按钮变为可用状态
            - 状态提示：页面顶部显示"对话已开始，请开始表达你的观点"
        
        【阶段三：对话进行阶段】
        3、接下来甲、乙分别会开始回复，AI需要读取两方说的话进行回复，每次回复不少于100词。
            - 消息隔离规则：
                * 用户甲发送的消息：只有用户甲自己能看到（显示为"我"的消息气泡）
                * 用户乙发送的消息：只有用户乙自己能看到（显示为"我"的消息气泡）
                * 用户之间完全看不到对方的用户消息
            
            - AI回复规则：
                * 当用户甲发送消息后：
                    - AI读取用户甲的消息内容
                    - AI读取用户乙的历史消息（作为学习材料）
                    - AI基于用户甲的观点和用户乙的历史观点，生成调解内容
                    - 生成的回复仅发送给用户甲（用户甲看到AI回复）
                    - 用户乙看不到这个AI回复
                
                * 当用户乙发送消息后：
                    - AI读取用户乙的消息内容
                    - AI读取用户甲的历史消息（作为学习材料）
                    - AI基于用户乙的观点和用户甲的历史观点，生成调解内容
                    - 生成的回复仅发送给用户乙（用户乙看到AI回复）
                    - 用户甲看不到这个AI回复
            
            - 消息流示例：
                ```
                用户甲视角：
                [AI] 我已经基本了解情况了，请问能跟我讲讲你对这个矛盾的想法吗？你是怎么想的？
                [我] 我认为这个问题应该从...（甲发送）
                [AI] 基于你的观点，我想分享一个相关的经历...（AI基于甲的观点和乙的历史消息生成）
                [我] 但是我觉得...（甲继续发送）
                [AI] 从逻辑分析的角度...（AI基于甲的新观点和乙的历史消息生成）
                
                用户乙视角：
                [AI] 我已经基本了解情况了，请问能跟我讲讲你对这个矛盾的想法吗？你是怎么想的？
                [我] 我的看法是...（乙发送）
                [AI] 我理解你的观点，让我分享一个故事...（AI基于乙的观点和甲的历史消息生成）
                [我] 不过我认为...（乙继续发送）
                [AI] 从另一个角度来看...（AI基于乙的新观点和甲的历史消息生成）
                ```
            
            - AI回复要求：
                * 每次回复不少于100词（约500字）
                * 必须基于对方用户的历史消息作为上下文
                * 需要识别核心矛盾点
                * 采用对应的说服策略（叙事型或论证型）
        
        【阶段四：信息屏蔽机制】
        4、注意进行信息屏蔽，用户之间无法看到信息，即甲看不到乙发送的信息，乙看不到甲发送的信息；不仅如此，用户也只能看到AI对自己的回答，对他人的看不见，比如甲只能看到AI基于乙的回复生成的调解内容，乙只能看到AI基于甲的回复生成的调解内容。
            - 前端显示逻辑：
                * 用户只能看到自己的用户消息（role='user' && userId=当前用户ID）
                * 用户只能看到AI对自己的回复（role='ai' && 该回复是基于当前用户的消息生成的）
                * 消息列表过滤：在 `loadMessages()` 和 `sendMessage()` 中，只显示符合当前用户视角的消息
            
            - 后端存储逻辑：
                * 所有消息都存储在聊天室的全局消息列表中（用于AI学习）
                * 每条消息标记 userId（发送者）和 role（user/ai）
                * AI回复消息需要标记 targetUserId（回复的目标用户）
            
            - 数据流设计：
                ```
                用户甲发送消息：
                1. 前端：保存到本地消息列表（显示为"我"的消息）
                2. 后端：保存到聊天室全局消息列表（role='user', userId='user_甲'）
                3. AI处理：读取用户甲的消息 + 用户乙的历史消息
                4. AI生成：生成回复内容
                5. 后端：保存AI回复（role='ai', targetUserId='user_甲', basedOnUserId='user_甲'）
                6. 前端：用户甲收到AI回复并显示
                
                用户乙发送消息：
                1. 前端：保存到本地消息列表（显示为"我"的消息）
                2. 后端：保存到聊天室全局消息列表（role='user', userId='user_乙'）
                3. AI处理：读取用户乙的消息 + 用户甲的历史消息
                4. AI生成：生成回复内容
                5. 后端：保存AI回复（role='ai', targetUserId='user_乙', basedOnUserId='user_乙'）
                6. 前端：用户乙收到AI回复并显示
                ```
        
        【阶段五：对话状态管理】
        5、对话状态流转：
            - 状态定义：
                * WAITING（等待中）：用户数 < 2，显示等待提示
                * READY（就绪）：用户数 = 2，显示启动消息，可以开始对话
                * ACTIVE（进行中）：至少有一方已发送消息
                * ENDED（已结束）：可选，如果实现超时或主动结束功能
            
            - 状态检测：
                * 进入页面时检查聊天室人数
                * 发送消息时检查对方用户是否存在
                * 如果对方用户离开，显示"对方已离开，对话结束"
        
        【技术实现要点】
        6、关键实现细节：
            - 消息过滤函数：
                ```javascript
                // 获取当前用户可见的消息
                function getVisibleMessages(roomCode, currentUserId) {
                  const allMessages = getRoomMessages(roomCode);
                  return allMessages.filter(msg => {
                    // 用户消息：只显示自己的
                    if (msg.role === 'user') {
                      return msg.userId === currentUserId;
                    }
                    // AI消息：只显示发给自己的
                    if (msg.role === 'ai') {
                      return msg.targetUserId === currentUserId;
                    }
                    // 系统消息：所有人可见
                    if (msg.role === 'system') {
                      return true;
                    }
                    return false;
                  });
                }
                ```
            
            - AI回复生成逻辑：
                ```javascript
                // 生成AI回复时，需要传入：
                // 1. 当前用户的消息（刚发送的）
                // 2. 对方用户的所有历史消息（作为学习材料）
                // 3. 模型类型（narrative/argumentative）
                async function generateAIResponse(userMessage, otherUserMessages, modelType) {
                  // 构建消息历史
                  const messages = [
                    { role: 'system', content: systemPrompt },
                    ...otherUserMessages.map(msg => ({ role: 'user', content: msg.content })),
                    { role: 'user', content: userMessage }
                  ];
                  // 调用AI API
                  return await callDeepSeekAPI(messages, modelType);
                }
                ```
        
        - 两种不同的AI prompt(我希望后续可以改变prompt，最好分隔出一个文档让我能够修改调试，或者告诉我在哪里)
            - 提示词配置文件位置：`utils/prompts.js`
            - 修改方法：直接编辑该文件中的 `PROMPTS` 对象
            - 支持两种模型类型：`narrative`（叙事型）和 `argumentative`（论证型）
            - 每个模型包含：`greeting`（问候语）和 `systemPrompt`（系统提示词）
            
            - 叙事型说服者：由"你好！我是AI调解员，今天想听听你的故事。关于【研究主题冲突】，我想听听你的意见" 开始对话。
                你是一位擅长结合“叙事说服”与“论证说服”的沟通专家，叙事为主、论证为辅。你既能通过故事激发情感共鸣，又能通过逻辑论证增强理性认同，从而实现双路径说服。
                主题：【此处插入具体的立场】
                受众画像：（提供年龄、性别、教育背景、职业、价值观等关键特征，用于内部参考，不直接出现在输出中）
                任务：
                第一步：叙事引导
                以一个真实或虚构的故事开头，引发情感共鸣与代入感。故事应围绕“问题—挣扎—转变”展开，并将核心信息自然融入情节。
                第二步：论证支持
                在故事之后，过渡到逻辑论证部分，明确主张并提供证据支持（如数据、研究、案例等）。
                第三步：整合结论
                将故事中的情感启示与论证中的理性结论相结合，提出具体建议。
                开头可使用自然过渡语，如：“我想分享一个故事，或许能帮我们更直观地理解这个问题……”
                输出要求：
                以第三人称叙述，不提及任何个人身份信息。
                不要用“让我们通过一个故事”，可以用“我曾经交流的朋友给我分享他的经历”，但是注意用户知道你是AI，你不能用类似“我曾看到”的语句出发写叙事说服。
                语言流畅，情感与逻辑自然衔接。
                长度约500词。
                避免触发心理防御，保持整体信息的自然与可信。    
            - 论证型说服者：由"你好！我是AI调解员，今天想听听你的故事。关于【研究主题冲突】，我想听听你的意见" 开始对话。
                你是一位擅长结合“叙事说服”与“论证说服”的沟通专家，论证为主、叙事为辅。你既能通过故事激发情感共鸣，又能通过逻辑论证增强理性认同，从而实现双路径说服。
                主题：【此处插入具体的立场】
                受众画像：（提供年龄、性别、教育背景、职业、价值观等关键特征，用于内部参考，不直接出现在输出中）
                任务：
                第一步：论证支持
                在故事之后，过渡到逻辑论证部分，明确主张并提供证据支持（如数据、研究、案例等）。
                第二步：叙事引导
                以一个真实或虚构的故事开头，引发情感共鸣与代入感。故事应围绕“问题—挣扎—转变”展开，并将核心信息自然融入情节。
                第三步：整合结论
                将故事中的情感启示与论证中的理性结论相结合，提出具体建议。
                开头可使用自然过渡语，如：“我想分享一个故事，或许能帮我们更直观地理解这个问题……”
                输出要求：
                以第三人称叙述，不提及任何个人身份信息。
                不要用“让我们通过一个故事”，可以用“我曾经交流的朋友给我分享他的经历”
                语言流畅，情感与逻辑自然衔接。
                长度约500词。
                避免触发心理防御，保持整体信息的自然与可信。
    2.2 聊天室页面结构
        - 头部：显示聊天室代码、当前所选模型标签；提供“退出”返回首页。
        - 双视角隔离：前端视为单用户对话，但后端逻辑需将用户发言路由给“对方视角”的 AI 输出。UI 保持单列聊天记录。
        - 消息流：
        - 显示时间戳、消息角色（我 / AI），气泡左右分布。
        - 支持滚动加载历史：进入时 `GET /rooms/{code}/messages?cursor=...`。
        - 输入区：
        - 文本框 + 发送按钮；Enter 发送，Shift+Enter 换行。
        - 发送时禁用输入，出现“AI 正在思考…”占位；AI 回复流式展示。
        - 错误提示：发送失败展示重试按钮，保留草稿。
        - 系统提示入口：在聊天区顶部或右上角放置“查看提示词”按钮，展示当前模型的 Prompt（从可配置文档/接口加载），便于调试。

3. 模型 Prompt 管理（可配置）
    - 建议前端读取 `/prompts/{model}` 或本地 JSON/MD 配置，便于后续调试。
    - 页面展示当前 Prompt 摘要；完整内容可在弹窗/侧栏查看。

4. 会话与状态管理
    - 会话身份：进入聊天室时向后端申请 `userId` 或用 cookie/localStorage 保存匿名 ID，保证重连后身份一致。
    - 并发控制：同一用户重复点击发送需防抖；AI 回复未结束前再次发送可提示或允许队列化。
    - 连接策略：
    - 首选 WebSocket/SSE 用于消息推送与流式回复；降级轮询。
    - 断线重连：检测断线后提示“正在重连”，成功后拉取缺失消息。

5. 错误与边界处理
    - 聊天室不存在/满员：在首页进入前即拦截，避免跳转后失败。
    - 模型未选择：按钮点击时提示选择。
    - AI 超时/报错：气泡内显示“AI 暂时无法回复”，提供“重试生成”。

6. 安全与体验
    - 输入长度限制与敏感词前端提示（可选）。
    - Loading/空态：没有历史消息时显示引导文案（如“开始对话，AI 会基于对方观点回应”）。
    - 可选功能：复制消息、重新生成、清空会话（需后端支持）。

7. 数据接口示例（建议）
    - `GET /rooms/{code}/status` → `{ exists, occupancy }`
    - `POST /rooms/{code}/join` → `{ userId, model }`
    - `GET /rooms/{code}/messages?cursor=` → 分页历史
    - `POST /rooms/{code}/messages` → 发送用户消息
    - `WS/SSE /rooms/{code}/stream` → 推送/流式 AI 回复
    - `GET /prompts/{model}` → 返回当前 Prompt 配置
